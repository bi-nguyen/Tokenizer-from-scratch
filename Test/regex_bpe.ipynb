{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"\"\"Docker là nền tảng cung cấp cho các công cụ, service để các developers, adminsystems có thể phát triển, thực thi, chạy các ứng dụng với containers. Hay nói một cách khác nó là một nền tảng để cung cấp cách để building, deploy và run các ứng dụng một cách dễ dàng trên nền tảng ảo hóa - \"Build once, run anywhere\". Hay nói một cách dễ hiểu như sau: Khi chúng ta muốn chạy app thì chúng ta phải thiết lập môi trường chạy cho nó. Thay vì chúng ta sẽ đi cài môi trường chạy cho nó thì chúng ta sẽ chạy docker.\n",
    "\n",
    "# Ứng dụng Docker chạy trong vùng chứa (container) có thể được sử dụng trên bất kỳ hệ thống nào: máy tính xách tay của nhà phát triển, hệ thống trên cơ sở hoặc trong hệ thống đám mây. Và là một công cụ tạo môi trường được \"đóng gói\" (còn gọi là Container) trên máy tính mà không làm tác động tới môi trường hiện tại của máy, môi trường trong Docker sẽ chạy độc lập.\n",
    "\n",
    "# Docker có thể làm việc trên nhiều nền tảng như Linux, Microsoft Windows và Apple OS X.\n",
    "# Virtualization host là gì ?\n",
    "\n",
    "# Khi chúng ta nói về Virtualization, nó đề cập đến việc nhập hệ điều hành Guest trên hệ điều hành máy chủ, cho phép các nhà phát triển chạy nhiều HĐH trên các máy ảo khác nhau trong khi tất cả chúng chạy trên cùng một máy chủ, do đó loại bỏ nhu cầu cung cấp thêm tài nguyên phần cứng.\n",
    "\n",
    "# Ưu điểm :\n",
    "\n",
    "# Kích hoạt nhiều hệ điều hành trên cùng một máy.\n",
    "# Nó rẻ hơn so với các phương pháp trước đây, do thiết lập cơ sở hạ tầng ít hơn / nhỏ gọn.\n",
    "# Nếu có bất kỳ trạng thái thất bại nào, thật dễ dàng để phục hồi và bảo trì.\n",
    "# Cung cấp nhanh hơn các ứng dụng và tài nguyên cần thiết cho các nhiệm vụ.\n",
    "# Tăng năng suất, hiệu quả và đáp ứng CNTT.\n",
    "# Virtualization host là gì ?\n",
    "# Từ kiến trúc VM ở trên, chúng ta có thể hình dung ra rằng 3 hệ điều hành Guest hoạt động như các máy ảo đang chạy trên một hệ điều hành máy chủ. Trong Virtualization, quá trình cấu hình lại phần cứng, phần sụn thủ công, cài đặt HĐH mới, cài đặt hệ điều hành mới có thể hoàn toàn tự động, tất cả các bước này được lưu trữ dưới dạng dữ liệu trong bất kỳ tệp nào của đĩa.\n",
    "\n",
    "# Trong Virtualization, mỗi ứng dụng và hệ điều hành sống trong một thùng chứa phần mềm riêng biệt có tên Virtural Machine (VM) , trong đó VM hoàn toàn tách biệt, tất cả các tài nguyên điện toán như CPU, lưu trữ và kết nối mạng được gộp chung với nhau. Virtural Machine (VM) về bản chất là một giả lập của một máy tính để thực thi các ứng dụng giống như một máy tính thật. VMs chạy trên một máy vật lý sử dụng một thứ gọi là “hypervisor”. Hypervisor có thể là phần cứng, phần mềm hoặc là một bản firmware nào đó có thể chạy trực tiếp trên máy thật (host machine) có chức năng cho nhiều máy ảo chạy trên nó. Host machine sẽ cung cấp cho VMs những tài nguyên như là RAM, CPU. Những tài nguyên đó sẽ được phân bổ giữa các VMs theo cách mà bạn cho là hợp lý. Nếu một VM chạy nhiều ứng dụng hoặc nặng thì bạn phải cung cấp tài nguyên cho nó nhiều tài nguyên hơn những VMs khác trên cùng một host machine.\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"xin chào\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_SPLIT_PATTERN = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(GPT_SPLIT_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xin', ' chào']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encode = list(text.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encode = list(map(int,text_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids,pairs:dict|None=None):\n",
    "    if pairs == None:\n",
    "        pairs = {}\n",
    "    for pair in zip(ids[:-1],ids[1:]):\n",
    "        pairs[pair] = pairs.get(pair,0) + 1\n",
    "    return pairs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def best_pair(pairs:dict):\n",
    "#     return max(pairs,key=pairs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_func(ids:list,best_pair:dict,idx:int):\n",
    "    '''\n",
    "    merge a best pair into a new token in the given ids.\n",
    "    \n",
    "    args:\n",
    "        ids: a list of token ids\n",
    "        best_pair: a tuple of two best pair\n",
    "        idx: a new idx for the best_pair\n",
    "    \n",
    "    return:\n",
    "        a new list of token ids with best_pair replaced by idx\n",
    "    '''\n",
    "    i = 0\n",
    "    new_ids = [] \n",
    "\n",
    "    while i<len(ids):\n",
    "        if i<len(ids)-1 and ids[i] == best_pair[0] and ids[i+1]==best_pair[1]:\n",
    "            new_ids.append(idx)\n",
    "            i+=2\n",
    "        else:\n",
    "            new_ids.append(ids[i])\n",
    "            i+=1\n",
    "    \n",
    "    return new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(ids:list,best_pair:tuple,idx:int):\n",
    "    i = 0\n",
    "    new_token = []\n",
    "    while i<len(ids):\n",
    "        if i<len(ids)-1 and ids[i] == best_pair[0] and ids[i+1] == best_pair[1]:\n",
    "            new_token.append(idx)\n",
    "            i+=2\n",
    "        else:\n",
    "            new_token.append(ids[i])\n",
    "            i+=1\n",
    "    return new_token\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks= re.findall(pattern,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {i:bytes([i]) for i in range(256)}\n",
    "merges ={}\n",
    "def train(text,vocabsize):\n",
    "    assert vocabsize >=256, \"Your vocabsize must be larger than 256\"\n",
    "    chunks= re.findall(pattern,text)\n",
    "    encoded_chunks = [list(ch.encode(\"UTF-8\")) for ch in chunks]\n",
    "    for i in range(vocabsize-256):\n",
    "        pairs = {}\n",
    "        for c in encoded_chunks:\n",
    "            pairs = get_stats(c,pairs)\n",
    "\n",
    "        if not pairs:\n",
    "            break\n",
    "\n",
    "        best_pair = max(pairs,key=pairs.get)\n",
    "        idx = 256+i\n",
    "        encoded_chunks = [merge(ids,best_pair,idx) for ids in encoded_chunks]\n",
    "        merges[best_pair] = idx\n",
    "        vocab[idx] = vocab[best_pair[0]] + vocab[best_pair[1]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(text,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(120, 105): 256,\n",
       " (256, 110): 257,\n",
       " (32, 99): 258,\n",
       " (258, 104): 259,\n",
       " (259, 195): 260,\n",
       " (260, 160): 261,\n",
       " (261, 111): 262}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_SPECIAL_TOKENS = {\n",
    "    '<|endoftext|>': 100257,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_TOKEN_IDX = {\n",
    "    100257: '<|endoftext|>',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids:list[int]):\n",
    "    decode_list  = b\"\".join([SPECIAL_TOKEN_IDX[i].encode(\"UTF-8\") if i in SPECIAL_TOKEN_IDX else vocab[i] for i in ids])\n",
    "    return decode_list.decode(\"UTF-8\",errors=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<\\|endoftext\\|>\n"
     ]
    }
   ],
   "source": [
    "for i in GPT_SPECIAL_TOKENS:\n",
    "    print(re.escape(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_chunks(chunk:list[int])->list[int]:\n",
    "    if len(chunk)<2:\n",
    "        return chunk\n",
    "\n",
    "    while True:\n",
    "        pair_chunk = get_stats(chunk)\n",
    "        if not pair_chunk:\n",
    "            break\n",
    "        min_pair = min(pair_chunk, key = lambda x: merges.get(x,float(\"inf\")))\n",
    "        idx = merges.get(min_pair,None)\n",
    "        if idx == None:\n",
    "            break \n",
    "        chunk = merge_func(chunk,min_pair,idx)\n",
    "    return chunk\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text:str)->list[int]:\n",
    "    chunks = re.findall(pattern,text)\n",
    "    ids = []\n",
    "    for c in chunks:\n",
    "        encoded_chunk = list(map(int,list(c.encode(\"UTF-8\"))))\n",
    "        ids.extend(encode_chunks(encoded_chunk))\n",
    "    return ids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text,special_token:dict|None=None):\n",
    "    special_patern = None\n",
    "    if special_token:\n",
    "        special_patern = \"(\"+\"|\".join([re.escape(i) for i in special_token]) + \")\"\n",
    "        special_patern  = re.compile(special_patern)\n",
    "        text = re.split(special_patern,text)\n",
    "    ids = []\n",
    "    for t in text:\n",
    "        if t in special_token:\n",
    "            ids.append(special_token[t])\n",
    "        else:\n",
    "            ids.extend(encode_text(t))\n",
    "    return ids\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(120, 105): 256,\n",
       " (256, 110): 257,\n",
       " (32, 99): 258,\n",
       " (258, 104): 259,\n",
       " (259, 195): 260,\n",
       " (260, 160): 261,\n",
       " (261, 111): 262}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"xin chào <|endoftext|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_text = encode(text,GPT_SPECIAL_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "100257",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vocab[\u001b[38;5;241m100257\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m,errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 100257"
     ]
    }
   ],
   "source": [
    "vocab[].decode(\"utf-8\",errors=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[257, 262, 32, 100257]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_text = decode(encode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
